---
title: "p8105_hw2_xw2962"
author: "Xiaoyu Wu"
date: "2023-09-26"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(haven)
library(readxl)
```

## Problem One 

#### Step One: Clean Data in `pols-month.csv`

```{r,message=FALSE}
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(mon,into=c("year","month","day"),sep="-",convert=TRUE) |>
# Seperate mon into year, month and day 
   mutate(month=month.abb[as.numeric(month)]) |>
# Replace month number with month name 
  mutate(
   prez_gop=case_match(
     prez_gop,
     0~"dem",
     1~"gop",
   )) |>
  mutate(
   prez_dem=case_match(
     prez_dem,
     0~"gop",
     1~"dem",
   )) |>
  relocate(year, month,day,prez_gop,prez_dem) |>
  pivot_longer(
   prez_gop:prez_dem,
   names_to = "president_title",
   values_to = "president"
   ) |>
# Create a president variable taking values gop and dem, and remove prez_dem and prez_gop
   select(-day) |>
# Remove the day variable
   select(-president_title)
pols_df
```

#### Step Two: Clean Data in `snp.csv`

```{r,message=FALSE}
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  mutate(date=as.Date(date,format="%m/%d/%y"),
         date=as.Date(ifelse(date>Sys.Date(),
                             format(date,"19y-%m-%d"),
                             format(date)))) |>
         separate(date,into=c("year","month","day")) |> 
# Use separate() to break up the variable mon into integer variables year, month, and day
   mutate(month=month.abb[as.numeric(month)],
   year=as.numeric(year)) |>
# Replace month number with month name
  select(-day) |> 
# Remove the day variable
  arrange(year, month) |>
# Arrange according to year and month
  relocate(year, month) 
# Organize so that year and month are the leading columns

snp_df
```

#### Step Three: Tidy Data in `unemployment.csv`

```{r, message=FALSE}
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |>
# Read in dataset 
  pivot_longer(
   jan:dec,
   names_to = "month",
   values_to = "unemployment_num"
   ) 
# Use pivot_longer function to switch from “wide” to “long” format;
unemployment_df
```

#### Join Datasets

```{r}
pols_snp = 
  left_join(pols_df,snp_df,by = c("year","month"))
# Join the datasets by merging snp into pols
pols_snp_unemployment=
  left_join(pols_snp,unemployment_df,by = c("year","month"))
# Join unemployment_df to the result dataset from above
pols_snp_unemployment
```

#### Short Description of Dataset

Dataset "pols_df" has `r ncol(pols_df)` variables: `r colnames(pols_df)`. In this dataset, there are `r nrow(pols_df)` rows. And there are `r ncol(pols_df)` columns. Here we consider variables "gov_gop", "sen_gop", "rep_gop", "gov_dem", "sen_dem", "rep_dem" and "president" to be important for analysis.

Dataset "snp_df" has `r ncol(snp_df)` variables: `r colnames(snp_df)`. In this dataset, there are `r nrow(snp_df)` rows. And there are `r ncol(snp_df)` columns. Here we consider variables "close" to be important for analysis.

Dataset "unemployment_df" has `r ncol(unemployment_df)` variables: `r colnames(unemployment_df)`. In this dataset, there are `r nrow(unemployment_df)` rows. And there are `r ncol(unemployment_df)` columns. Here we consider variables "unemployment_num" to be important for analysis.

The joining dataset "pols_snp_unemployment" has `r ncol(pols_snp_unemployment)` variables: `r colnames(pols_snp_unemployment)`. In this dataset, there are `r nrow(pols_snp_unemployment)` rows. And there are `r ncol(pols_snp_unemployment)` columns. Here we consider variables "gov_gop", "sen_gop", "rep_gop", "gov_dem", "sen_dem", "rep_dem", "president","close" and "unemployment_num" to be important for analysis.

## Problem Two

#### Import, Clean, and Organize the Data for `Mr. Trash Wheel`
```{r}
mr_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",range="A2:N549") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |>
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="mr_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification 
mr_trash_wheel_df
```

#### Import, Clean, and Organize the Data for `Professor Trash Wheel`

```{r}
professor_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",2,range="A2:M96") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="professor_trash_wheel") |>
  relocate(trash_wheel_name) |> 
# Add a variable for clear identification
  mutate(year=as.character("year"))
professor_trash_wheel_df
```

#### Import, Clean, and Organize the Data for `Gwynnda Trash Wheel`

```{r}
Gwynnda_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",4,range="A2:K108") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="Gwynnda_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification
Gwynnda_trash_wheel_df
Gwynnda_trash_wheel_df_july=filter(Gwynnda_trash_wheel_df,month=="July" )
Gwynnda_trash_wheel_df_july
# Filter out the Gwynnda_trash_wheel data in july 
```

#### Combine these with the `Mr. Trash Wheel` Dataset to Create Single  Tidy Dataset

```{r}
mr_professor_Gwynnda=
  left_join(mr_trash_wheel_df,professor_trash_wheel_df,Gwynnda_trash_wheel_df,by=c("trash_wheel_name","month","dumpster","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","glass_bottles","grocery_bags","chip_bags","homes_powered"))
mr_professor_Gwynnda
```

#### Description

Dataset "mr_professor_Gwynnda" has 15 variables: `r colnames(mr_professor_Gwynnda)`. In this dataset, there are `r nrow(mr_professor_Gwynnda)` rows or observations. And there are `r ncol(mr_professor_Gwynnda)` columns or variables. 

Here, we consider "weight_tons","volume_cubic_yards" and "homes_powered" to be key variables. The variable "weight_tons" has mean `r mean(mr_professor_Gwynnda$weight_tons)` and standard deviation `r sd(mr_professor_Gwynnda$weight_tons)`. The variable "volume_cubic_yards" has mean `r mean(mr_professor_Gwynnda$volume_cubic_yards)` and standard deviation `r sd(mr_professor_Gwynnda$volume_cubic_yards)`. The variable "homes_powered" has mean `r mean(mr_professor_Gwynnda$homes_powered)` and standard deviation `r sd(mr_professor_Gwynnda$homes_powered)`. 

The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trash_wheel_df$weight_tons)`. 

The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(Gwynnda_trash_wheel_df_july$cigarette_butts)`.  

## Problem Three

#### Import, Clean and Tidy Dataset `MCI_baseline.csv`

```{r, warning=FALSE,message=FALSE}
mci_baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  mutate(age_at_onset=as.numeric(age_at_onset)) |>
  filter(age_at_onset!=".") |> 
# Remove any participants who do not meet the stated inclusion criteria
  rename("study_id" = "id") 

mci_baseline_df_noncleaned = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
  mutate(sex = recode(sex, "1" = "male", "0" = "female"))

mci_baseline_df_female=filter(mci_baseline_df_noncleaned,sex=="female" )
# Filter out participants who are females 
mci_baseline_df_female_carriers=filter(mci_baseline_df_female, apoe4=="carrier")
# Filter out participants who are females and who have apoe4 carriers 
mci_baseline_df
```

#### Discussion 

Dataset "mci_baseline_df" has `r ncol(mci_baseline_df)` variables: `r colnames(mci_baseline_df)`. In this dataset, there are `r nrow(mci_baseline_df)` participants. Of these, 97 devlops MCI. The average baseline age is `r mean(mci_baseline_df$age_at_onset)`. `r ((nrow(mci_baseline_df_female_carriers))/(nrow(mci_baseline_df_female)))*100` % of women in the study are APOE4 carriers.    

#### Import, Clean and Tidy Dataset `mci_amyloid.csv`

```{r,message=FALSE}
mci_amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na() |>
# Remove any participants who do not meet the stated inclusion criteria
  pivot_longer(
   baseline:time_8,
   names_to = "time",
   values_to = "time_value"
   ) |>
# Use pivot_longer function to switch from “wide” to “long” format
   arrange(time,study_id)
# Arrange the dataset according to time and study_id

mci_amyloid_df_unpivot= 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na()

mci_amyloid_df 
```


#### Discussion 
Dataset "mci_amyloid_df" has `r ncol(mci_amyloid_df)` variables: `r colnames(mci_amyloid_df)`. In this dataset, there are `r nrow(mci_amyloid_df)` rows. 

## Join dataset 

```{r EVAL=FALSE}
baseline_amyloid= merge(mci_baseline_df,mci_amyloid_df_unpivot, 
             by="study_id")
# Calculate participants appear in both datasets 
unqiue_baseline=setdiff(mci_baseline_df_noncleaned$id, mci_amyloid_df_unpivot$study_id)
length(unqiue_baseline)
unqiue_amyloid=setdiff(mci_amyloid_df_unpivot$study_id, mci_baseline_df_noncleaned$id)
length(unqiue_amyloid)
# Calculatethe number of unqiue participants in each datasets. 
baseline_amyloid_merge= merge(mci_baseline_df,mci_amyloid_df, 
             by="study_id")
# Merge two datasets so that only participants who appear in both datasets are retained 
```

#### Discussion 

There are 146 unqiue partcipants in "MCI_baseline.csv" dataset and there are 10 unique participants in "mci_amyloid.csv" dataset. 

Only `r nrow(baseline_amyloid)` participants appear in both the baseline and amyloid datasets. 

For the resulting merged dataset, there are `r ncol(baseline_amyloid_merge)` variables, they are `r colnames(baseline_amyloid_merge)`.

#### Export Result as CSV

```{r}
write_csv(baseline_amyloid_merge,"baseline_amyloid_merge.csv")
```



