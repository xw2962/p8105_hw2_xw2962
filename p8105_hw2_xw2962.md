p8105_hw2_xw2962
================
Xiaoyu Wu
2023-09-26

``` r
library(tidyverse)
library(haven)
library(readxl)
```

## Problem One

#### Step One: Clean Data in `pols-month.csv`

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(mon, into = c("year", "month_day"), sep = 4) |>
  separate(month_day, into = c("month","day"), sep = 3) |>
# Use separate() to break up the variable mon into integer variables year, month, and day
  mutate(month = recode(month, "-01" = "jan", "-02" = "feb","-03" = "mar","-04" = "apr","-05" = "may","-06" = "jun","-07" = "jul","-08" = "aug","-09" = "sep","-10" = "oct","-11" = "nov","-12" = "dec")) |> 
# Replace month number with month name 
  mutate(day=recode(day,"-15"="15")) |>
  mutate(
   prez_gop=case_match(
     prez_gop,
     0~"dem",
     1~"gop",
   )) |>
  mutate(
   prez_dem=case_match(
     prez_dem,
     0~"gop",
     1~"dem",
   )) |>
  relocate(year, month,day,prez_gop,prez_dem) |>
  pivot_longer(
   prez_gop:prez_dem,
   names_to = "president_title",
   values_to = "president"
   ) |>
# Create a president variable taking values gop and dem, and remove prez_dem and prez_gop
   select(-day) |>
# Remove the day variable
   select(-president_title)
pols_df
```

    ## # A tibble: 1,644 × 9
    ##    year  month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <chr> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1 1947  jan        23      51     253      23      45     198 dem      
    ##  2 1947  jan        23      51     253      23      45     198 dem      
    ##  3 1947  feb        23      51     253      23      45     198 dem      
    ##  4 1947  feb        23      51     253      23      45     198 dem      
    ##  5 1947  mar        23      51     253      23      45     198 dem      
    ##  6 1947  mar        23      51     253      23      45     198 dem      
    ##  7 1947  apr        23      51     253      23      45     198 dem      
    ##  8 1947  apr        23      51     253      23      45     198 dem      
    ##  9 1947  may        23      51     253      23      45     198 dem      
    ## 10 1947  may        23      51     253      23      45     198 dem      
    ## # ℹ 1,634 more rows

#### Step Two: Clean Data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(date, into = c("month", "day_year"), sep = 2) |>
  separate(day_year, into = c("day","year"), sep = 2) |>
# Use separate() to break up the variable mon into integer variables year, month, and day
  mutate(month = recode(month, "1/" = "jan", "2/" = "feb","3/" = "mar","4/" = "apr","5/" = "may","6/" = "jun","7/" = "jul","8/" = "aug","9/" = "sep","10" = "oct","11" = "nov","12" = "dec")) |> 
# Replace month number with month name
  select(-day) |> 
# Remove the day variable
  arrange(year, month) |>
# Arrange according to year and month
  relocate(year, month) |>
# Organize so that year and month are the leading columns
  separate(year, into = c("null", "year"), sep = 1) |>
  select(-null)
# Remove prefix "/" in the column "year"
snp_df
```

    ## # A tibble: 787 × 3
    ##    year  month close
    ##    <chr> <chr> <dbl>
    ##  1 00    dec   1320.
    ##  2 00    nov   1315.
    ##  3 00    oct   1429.
    ##  4 01    dec   1148.
    ##  5 01    nov   1139.
    ##  6 01    oct   1060.
    ##  7 02    dec    880.
    ##  8 02    nov    936.
    ##  9 02    oct    886.
    ## 10 03    dec   1112.
    ## # ℹ 777 more rows

#### Step Three: Tidy Data in `unemployment.csv`

``` r
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |>
# Read in dataset 
  pivot_longer(
   jan:dec,
   names_to = "month",
   values_to = "unemployment_num"
   ) |>
# Use pivot_longer function to switch from “wide” to “long” format;
  mutate(year=as.character("year"))
# Mutate year from dbl to character 
unemployment_df
```

    ## # A tibble: 816 × 3
    ##    year  month unemployment_num
    ##    <chr> <chr>            <dbl>
    ##  1 year  jan                3.4
    ##  2 year  feb                3.8
    ##  3 year  mar                4  
    ##  4 year  apr                3.9
    ##  5 year  may                3.5
    ##  6 year  jun                3.6
    ##  7 year  jul                3.6
    ##  8 year  aug                3.9
    ##  9 year  sep                3.8
    ## 10 year  oct                3.7
    ## # ℹ 806 more rows

#### Join Datasets

``` r
pols_snp = 
  left_join(pols_df,snp_df,by = "year","month")
pols_snp
```

    ## # A tibble: 1,644 × 11
    ##    year  month.x gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1 1947  jan          23      51     253      23      45     198 dem      
    ##  2 1947  jan          23      51     253      23      45     198 dem      
    ##  3 1947  feb          23      51     253      23      45     198 dem      
    ##  4 1947  feb          23      51     253      23      45     198 dem      
    ##  5 1947  mar          23      51     253      23      45     198 dem      
    ##  6 1947  mar          23      51     253      23      45     198 dem      
    ##  7 1947  apr          23      51     253      23      45     198 dem      
    ##  8 1947  apr          23      51     253      23      45     198 dem      
    ##  9 1947  may          23      51     253      23      45     198 dem      
    ## 10 1947  may          23      51     253      23      45     198 dem      
    ## # ℹ 1,634 more rows
    ## # ℹ 2 more variables: month.y <chr>, close <dbl>

``` r
# Join the datasets by merging snp into pols
pols_snp_unemployment=
  left_join(pols_snp,unemployment_df,by = "year","month")
# Join unemployment_df to the result dataset from above
pols_snp_unemployment
```

    ## # A tibble: 1,644 × 13
    ##    year  month.x gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1 1947  jan          23      51     253      23      45     198 dem      
    ##  2 1947  jan          23      51     253      23      45     198 dem      
    ##  3 1947  feb          23      51     253      23      45     198 dem      
    ##  4 1947  feb          23      51     253      23      45     198 dem      
    ##  5 1947  mar          23      51     253      23      45     198 dem      
    ##  6 1947  mar          23      51     253      23      45     198 dem      
    ##  7 1947  apr          23      51     253      23      45     198 dem      
    ##  8 1947  apr          23      51     253      23      45     198 dem      
    ##  9 1947  may          23      51     253      23      45     198 dem      
    ## 10 1947  may          23      51     253      23      45     198 dem      
    ## # ℹ 1,634 more rows
    ## # ℹ 4 more variables: month.y <chr>, close <dbl>, month <chr>,
    ## #   unemployment_num <dbl>

#### Short Description of Dataset

Dataset “pols_df” has 9 variables: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president. In this dataset, there
are 1644 rows. And there are 9 columns. Here we consider variables
“gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”, “sen_dem”, “rep_dem” and
“president” to be important for analysis.

Dataset “snp_df” has 3 variables: year, month, close. In this dataset,
there are 787 rows. And there are 3 columns. Here we consider variables
“close” to be important for analysis.

Dataset “unemployment_df” has 3 variables: year, month,
unemployment_num. In this dataset, there are 816 rows. And there are 3
columns. Here we consider variables “unemployment_num” to be important
for analysis.

The joining dataset “pols_snp_unemployment” has 13 variables: year,
month.x, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
president, month.y, close, month, unemployment_num. In this dataset,
there are 1644 rows. And there are 13 columns. Here we consider
variables “gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”, “sen_dem”,
“rep_dem”, “president”,“close” and “unemployment_num” to be important
for analysis.

## Problem Two

#### Import, Clean, and Organize the Data for `Mr. Trash Wheel`

``` r
mr_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",range="A2:N549") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |>
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="mr_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification 
mr_trash_wheel_df
```

    ## # A tibble: 486 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 476 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Professor Trash Wheel`

``` r
professor_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",2,range="A2:M96") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="professor_trash_wheel") |>
  relocate(trash_wheel_name) |> 
# Add a variable for clear identification
  mutate(year=as.character("year"))
professor_trash_wheel_df
```

    ## # A tibble: 82 × 14
    ##    trash_wheel_name      dumpster month    year  date                weight_tons
    ##    <chr>                    <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 professor_trash_wheel        1 January  year  2017-01-02 00:00:00        1.79
    ##  2 professor_trash_wheel        2 January  year  2017-01-30 00:00:00        1.58
    ##  3 professor_trash_wheel        3 February year  2017-02-26 00:00:00        2.32
    ##  4 professor_trash_wheel        4 February year  2017-02-26 00:00:00        3.72
    ##  5 professor_trash_wheel        5 February year  2017-02-28 00:00:00        1.45
    ##  6 professor_trash_wheel        6 March    year  2017-03-30 00:00:00        1.71
    ##  7 professor_trash_wheel        7 April    year  2017-04-01 00:00:00        1.82
    ##  8 professor_trash_wheel        8 April    year  2017-04-20 00:00:00        2.37
    ##  9 professor_trash_wheel        9 May      year  2017-05-10 00:00:00        2.64
    ## 10 professor_trash_wheel       10 May      year  2017-05-26 00:00:00        2.78
    ## # ℹ 72 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Gwynnda Trash Wheel`

``` r
Gwynnda_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",4,range="A2:K108") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="Gwynnda_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification
Gwynnda_trash_wheel_df
```

    ## # A tibble: 17 × 12
    ##    trash_wheel_name    dumpster month   year date                weight_tons
    ##    <chr>                  <dbl> <chr>  <dbl> <dttm>                    <dbl>
    ##  1 Gwynnda_trash_wheel        1 July    2021 2021-07-03 00:00:00        0.93
    ##  2 Gwynnda_trash_wheel        2 July    2021 2021-07-07 00:00:00        2.26
    ##  3 Gwynnda_trash_wheel        3 July    2021 2021-07-07 00:00:00        1.62
    ##  4 Gwynnda_trash_wheel        4 July    2021 2021-07-16 00:00:00        1.76
    ##  5 Gwynnda_trash_wheel        5 July    2021 2021-07-30 00:00:00        1.53
    ##  6 Gwynnda_trash_wheel        6 August  2021 2021-08-11 00:00:00        2.06
    ##  7 Gwynnda_trash_wheel        7 August  2021 2021-08-14 00:00:00        1.9 
    ##  8 Gwynnda_trash_wheel        8 August  2021 2021-08-16 00:00:00        2.16
    ##  9 Gwynnda_trash_wheel        9 August  2021 2021-08-16 00:00:00        2.6 
    ## 10 Gwynnda_trash_wheel       10 August  2021 2021-08-17 00:00:00        3.21
    ## 11 Gwynnda_trash_wheel       11 August  2021 2021-08-17 00:00:00        2.44
    ## 12 Gwynnda_trash_wheel       12 August  2021 2021-08-18 00:00:00        2.62
    ## 13 Gwynnda_trash_wheel       13 August  2021 2021-08-19 00:00:00        2.92
    ## 14 Gwynnda_trash_wheel       14 August  2021 2021-08-19 00:00:00        2.93
    ## 15 Gwynnda_trash_wheel       15 August  2021 2021-08-20 00:00:00        3.31
    ## 16 Gwynnda_trash_wheel       16 August  2021 2021-08-24 00:00:00        2.7 
    ## 17 Gwynnda_trash_wheel       17 August  2021 2021-08-25 00:00:00        2.1 
    ## # ℹ 6 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   homes_powered <dbl>

``` r
Gwynnda_trash_wheel_df_july=filter(Gwynnda_trash_wheel_df,month=="July" )
Gwynnda_trash_wheel_df_july
```

    ## # A tibble: 5 × 12
    ##   trash_wheel_name    dumpster month  year date                weight_tons
    ##   <chr>                  <dbl> <chr> <dbl> <dttm>                    <dbl>
    ## 1 Gwynnda_trash_wheel        1 July   2021 2021-07-03 00:00:00        0.93
    ## 2 Gwynnda_trash_wheel        2 July   2021 2021-07-07 00:00:00        2.26
    ## 3 Gwynnda_trash_wheel        3 July   2021 2021-07-07 00:00:00        1.62
    ## 4 Gwynnda_trash_wheel        4 July   2021 2021-07-16 00:00:00        1.76
    ## 5 Gwynnda_trash_wheel        5 July   2021 2021-07-30 00:00:00        1.53
    ## # ℹ 6 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   homes_powered <dbl>

``` r
# Filter out the Gwynnda_trash_wheel data in july 
```

#### Combine these with the `Mr. Trash Wheel` Dataset to Create Single Tidy Dataset

``` r
mr_professor_Gwynnda=
  left_join(mr_trash_wheel_df,professor_trash_wheel_df,Gwynnda_trash_wheel_df,by=c("trash_wheel_name","month","dumpster","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","glass_bottles","grocery_bags","chip_bags","homes_powered"))
mr_professor_Gwynnda
```

    ## # A tibble: 486 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 476 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   homes_powered <dbl>

#### Description

Dataset “mr_professor_Gwynnda” has 15 variables: trash_wheel_name,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
grocery_bags, chip_bags, sports_balls, homes_powered. In this dataset,
there are 486 rows or observations. And there are 15 columns or
variables.

Here, we consider “weight_tons”,“volume_cubic_yards” and “homes_powered”
to be key variables. The variable “weight_tons” has mean 3.2077778 and
standard deviation 0.7420151. The variable “volume_cubic_yards” has mean
15.3847737 and standard deviation 1.4366681. The variable
“homes_powered” has mean 53.462963 and standard deviation 12.3669181.

The total weight of trash collected by Professor Trash Wheel is 162.54.

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

## Problem Three

#### Import, Clean and Tidy Dataset `MCI_baseline.csv`

``` r
mci_baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  mutate(age_at_onset=as.numeric(age_at_onset)) |>
  filter(age_at_onset!=".") |> 
# Remove any participants who do not meet the stated inclusion criteria
  rename("study_id" = "id") 

mci_baseline_df_female=filter(mci_baseline_df,sex=="female" )
# Filter out participants who are females 
mci_baseline_df_female_carriers=filter(mci_baseline_df_female, apoe4=="carrier")
# Filter out participants who are females and who have apoe4 carriers 
mci_baseline_df
```

    ## # A tibble: 97 × 6
    ##    study_id current_age sex    education apoe4       age_at_onset
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>              <dbl>
    ##  1        3        62.5 male          16 carrier             66.8
    ##  2        5        66   male          16 non_carrier         68.7
    ##  3        7        66.5 male          18 non_carrier         74  
    ##  4       13        63.1 male          12 carrier             69  
    ##  5       14        58.4 female        20 non_carrier         66.2
    ##  6       18        67.8 male          16 non_carrier         69.8
    ##  7       22        67.3 female        20 carrier             74.6
    ##  8       26        64.8 female        20 carrier             71.1
    ##  9       30        66.3 female        12 non_carrier         73.1
    ## 10       39        68.3 female        16 carrier             70.2
    ## # ℹ 87 more rows

#### Discussion

Dataset “mci_baseline_df” has 6 variables: study_id, current_age, sex,
education, apoe4, age_at_onset. In this dataset, there are 483
participants. Of these, 97 devlops MCI. The average baseline age is
70.2628866. 65.2173913 % of women in the study are APOE4 carriers.

#### Import, Clean and Tidy Dataset `mci_amyloid.csv`

``` r
mci_amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na() 
# Remove any participants who do not meet the stated inclusion criteria
mci_amyloid_df 
```

    ## # A tibble: 347 × 6
    ##    study_id baseline    time_2      time_4      time_6      time_8     
    ##       <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1        2 0.107481183 0.109157373 0.109457839 0.105729713 0.10661845 
    ##  2        4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ##  3        5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ##  4        6 0.112426974 0.112853415 0.11143945  0.110279277 0.114982747
    ##  5       11 0.109119335 0.109316496 0.1114037   0.108586573 0.108993335
    ##  6       12 0.112042298 0.114167481 0.109859682 0.106842794 0.107334106
    ##  7       13 0.110300505 0.108534417 0.108100808 0.109229662 0.104861901
    ##  8       16 0.110218888 0.113741328 0.111101474 0.108852437 0.109556166
    ##  9       17 0.108399246 0.113317542 0.105909034 0.107196914 0.110199133
    ## 10       18 0.114137255 0.107093264 0.110872562 0.108982605 0.106873903
    ## # ℹ 337 more rows

#### Discussion

Dataset “mci_amyloid_df” has 6 variables: study_id, baseline, time_2,
time_4, time_6, time_8. In this dataset, there are 347 rows or
participants. And there are 6 columns or variables.

## Join dataset

``` r
baseline_amyloid= merge(mci_baseline_df,mci_amyloid_df, 
             by="study_id")
```

#### Discussion

Only 66 participants appear in both the baseline and amyloid datasets.
And there are 11 variables, they are study_id, current_age, sex,
education, apoe4, age_at_onset, baseline, time_2, time_4, time_6,
time_8.

#### Export Result as CSV

``` r
write_csv(baseline_amyloid,"baseline_amyloid.csv")
```
