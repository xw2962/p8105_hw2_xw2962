p8105_hw2_xw2962
================
Xiaoyu Wu
2023-09-26

``` r
library(tidyverse)
library(haven)
library(readxl)
```

## Problem One

#### Step One: Clean Data in `pols-month.csv`

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
# seperate month into year, month_num and day. 
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
# create a variable called "president" by recoding prez_gop
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
# arrange table and delete day and columns starts with "prez" 
pols_df
```

    ## # A tibble: 822 × 11
    ##     year month     month_num gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <int> <chr>         <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January           1      23      51     253      23      45     198
    ##  2  1947 February          2      23      51     253      23      45     198
    ##  3  1947 March             3      23      51     253      23      45     198
    ##  4  1947 April             4      23      51     253      23      45     198
    ##  5  1947 May               5      23      51     253      23      45     198
    ##  6  1947 June              6      23      51     253      23      45     198
    ##  7  1947 July              7      23      51     253      23      45     198
    ##  8  1947 August            8      23      51     253      23      45     198
    ##  9  1947 September         9      23      51     253      23      45     198
    ## 10  1947 October          10      23      51     253      23      45     198
    ## # ℹ 812 more rows
    ## # ℹ 2 more variables: president <chr>, month_abb <chr>

#### Step Two: Clean Data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  mutate(date=as.Date(date,format="%m/%d/%y"),
         date=as.Date(ifelse(date>Sys.Date(),
                             format(date,"19y-%m-%d"),
                             format(date)))) |>
         separate(date,into=c("year","month","day")) |> 
# Use separate() to break up the variable mon into integer variables year, month, and day
   mutate(month=month.abb[as.numeric(month)],
   year=as.numeric(year)) |>
# Replace month number with month name
  select(-day) |> 
# Remove the day variable
  arrange(year, month) |>
# Arrange according to year and month
  relocate(year, month) 
# Organize so that year and month are the leading columns

snp_df
```

    ## # A tibble: 787 × 3
    ##     year month close
    ##    <dbl> <chr> <dbl>
    ##  1  1969 Apr   104. 
    ##  2  1969 Aug    95.5
    ##  3  1969 Dec    92.1
    ##  4  1969 Feb    98.1
    ##  5  1969 Jan   103. 
    ##  6  1969 Jul    91.8
    ##  7  1969 Jun    97.7
    ##  8  1969 Mar   102. 
    ##  9  1969 May   103. 
    ## 10  1969 Nov    93.8
    ## # ℹ 777 more rows

#### Step Three: Tidy Data in `unemployment.csv`

``` r
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |>
# Read in dataset 
  pivot_longer(
   jan:dec,
   names_to = "month",
   values_to = "unemployment_num"
   ) 
# Use pivot_longer function to switch from “wide” to “long” format;
unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month unemployment_num
    ##    <dbl> <chr>            <dbl>
    ##  1  1948 jan                3.4
    ##  2  1948 feb                3.8
    ##  3  1948 mar                4  
    ##  4  1948 apr                3.9
    ##  5  1948 may                3.5
    ##  6  1948 jun                3.6
    ##  7  1948 jul                3.6
    ##  8  1948 aug                3.9
    ##  9  1948 sep                3.8
    ## 10  1948 oct                3.7
    ## # ℹ 806 more rows

#### Join Datasets

``` r
pols_snp = 
  left_join(pols_df,snp_df,by=c("year","month")) |> 
  arrange(year,month)
# Join the datasets by merging snp into pols
pols_snp_unemployment=
  left_join(pols_snp,unemployment_df,by=c("year","month")) |> 
  arrange(year,month)
# Join unemployment_df to the result dataset from above
pols_snp_unemployment
```

    ## # A tibble: 822 × 13
    ##     year month    month_num gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <dbl> <chr>        <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 April            4      23      51     253      23      45     198
    ##  2  1947 August           8      23      51     253      23      45     198
    ##  3  1947 December        12      24      51     253      23      45     198
    ##  4  1947 February         2      23      51     253      23      45     198
    ##  5  1947 January          1      23      51     253      23      45     198
    ##  6  1947 July             7      23      51     253      23      45     198
    ##  7  1947 June             6      23      51     253      23      45     198
    ##  8  1947 March            3      23      51     253      23      45     198
    ##  9  1947 May              5      23      51     253      23      45     198
    ## 10  1947 November        11      24      51     253      23      45     198
    ## # ℹ 812 more rows
    ## # ℹ 4 more variables: president <chr>, month_abb <chr>, close <dbl>,
    ## #   unemployment_num <dbl>

#### Short Description of Dataset

Dataset “pols_df” has 11 variables: year, month, month_num, gov_gop,
sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, month_abb. In
this dataset, there are 822 rows. And there are 11 columns. Here we
consider variables “gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”,
“sen_dem”, “rep_dem” and “president” to be important for analysis.

Dataset “snp_df” has 3 variables: year, month, close. In this dataset,
there are 787 rows. And there are 3 columns. Here we consider variables
“close” to be important for analysis.

Dataset “unemployment_df” has 3 variables: year, month,
unemployment_num. In this dataset, there are 816 rows. And there are 3
columns. Here we consider variables “unemployment_num” to be important
for analysis.

The joining dataset “pols_snp_unemployment” has 13 variables: year,
month, month_num, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
president, month_abb, close, unemployment_num. In this dataset, there
are 822 rows. And there are 13 columns. Here we consider variables
“gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”, “sen_dem”, “rep_dem”,
“president”,“close” and “unemployment_num” to be important for analysis.

## Problem Two

#### Import, Clean, and Organize the Data for `Mr. Trash Wheel`

``` r
mr_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",range="A2:N586") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |>
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="mr_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification 
mr_trash_wheel_df
```

    ## # A tibble: 584 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Professor Trash Wheel`

``` r
professor_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",2,range="A2:M108") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="professor_trash_wheel") |>
  relocate(trash_wheel_name) |> 
# Add a variable for clear identification
  mutate(year=as.character("year"))
professor_trash_wheel_df
```

    ## # A tibble: 106 × 14
    ##    trash_wheel_name      dumpster month    year  date                weight_tons
    ##    <chr>                    <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 professor_trash_wheel        1 January  year  2017-01-02 00:00:00        1.79
    ##  2 professor_trash_wheel        2 January  year  2017-01-30 00:00:00        1.58
    ##  3 professor_trash_wheel        3 February year  2017-02-26 00:00:00        2.32
    ##  4 professor_trash_wheel        4 February year  2017-02-26 00:00:00        3.72
    ##  5 professor_trash_wheel        5 February year  2017-02-28 00:00:00        1.45
    ##  6 professor_trash_wheel        6 March    year  2017-03-30 00:00:00        1.71
    ##  7 professor_trash_wheel        7 April    year  2017-04-01 00:00:00        1.82
    ##  8 professor_trash_wheel        8 April    year  2017-04-20 00:00:00        2.37
    ##  9 professor_trash_wheel        9 May      year  2017-05-10 00:00:00        2.64
    ## 10 professor_trash_wheel       10 May      year  2017-05-26 00:00:00        2.78
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Gwynnda Trash Wheel`

``` r
Gwynnda_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",4,range="A2:L157") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="Gwynnda_trash_wheel") |>
  mutate(year=as.character(year)) |>
  relocate(trash_wheel_name)
# Add a variable for clear identification
Gwynnda_trash_wheel_df
```

    ## # A tibble: 155 × 13
    ##    trash_wheel_name    dumpster month  year  date                weight_tons
    ##    <chr>                  <dbl> <chr>  <chr> <dttm>                    <dbl>
    ##  1 Gwynnda_trash_wheel        1 July   2021  2021-07-03 00:00:00        0.93
    ##  2 Gwynnda_trash_wheel        2 July   2021  2021-07-07 00:00:00        2.26
    ##  3 Gwynnda_trash_wheel        3 July   2021  2021-07-07 00:00:00        1.62
    ##  4 Gwynnda_trash_wheel        4 July   2021  2021-07-16 00:00:00        1.76
    ##  5 Gwynnda_trash_wheel        5 July   2021  2021-07-30 00:00:00        1.53
    ##  6 Gwynnda_trash_wheel        6 August 2021  2021-08-11 00:00:00        2.06
    ##  7 Gwynnda_trash_wheel        7 August 2021  2021-08-14 00:00:00        1.9 
    ##  8 Gwynnda_trash_wheel        8 August 2021  2021-08-16 00:00:00        2.16
    ##  9 Gwynnda_trash_wheel        9 August 2021  2021-08-16 00:00:00        2.6 
    ## 10 Gwynnda_trash_wheel       10 August 2021  2021-08-17 00:00:00        3.21
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
Gwynnda_trash_wheel_df_july=filter(Gwynnda_trash_wheel_df,month=="July" )
Gwynnda_trash_wheel_df_july_year=filter(Gwynnda_trash_wheel_df_july,year=="2021")
# Filter out the Gwynnda_trash_wheel data in july 
```

#### Combine these with the `Mr. Trash Wheel` Dataset to Create Single Tidy Dataset

``` r
mr_professor_Gwynnda=
  bind_rows(mr_trash_wheel_df,professor_trash_wheel_df,Gwynnda_trash_wheel_df) |>
  janitor::clean_names() |>
  select(trash_wheel_name,everything())

mr_professor_Gwynnda
```

    ## # A tibble: 845 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

#### Description

Dataset “mr_professor_Gwynnda” has 15 variables: trash_wheel_name,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, sports_balls, homes_powered. In this dataset,
there are 845 rows or observations. And there are 15 columns or
variables.

Here, we consider “weight_tons”,“volume_cubic_yards” and “homes_powered”
to be key variables. The variable “weight_tons” has mean 3.0094793 and
standard deviation 0.8135678. The variable “volume_cubic_yards” has mean
15.1349112 and standard deviation 1.3457939. The variable
“homes_powered” has mean 50.1579882 and standard deviation 13.5594639.

The total weight of trash collected by Professor Trash Wheel is 216.26.

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

## Problem Three

#### Import, Clean and Tidy Dataset `MCI_baseline.csv`

``` r
mci_baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  mutate(age_at_onset=as.numeric(age_at_onset)) |>
  filter(age_at_onset!=".") |> 
# Remove any participants who do not meet the stated inclusion criteria
  rename("study_id" = "id") 

mci_baseline_df_noncleaned = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |> 
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier"))

mci_baseline_df_female=filter(mci_baseline_df_noncleaned,sex=="female" )
# Filter out participants who are females 
mci_baseline_df_female_carriers=filter(mci_baseline_df_female,apoe4=="carrier")
# Filter out participants who are females and who have apoe4 carriers 

mci_baseline_df
```

    ## # A tibble: 97 × 6
    ##    study_id current_age sex    education apoe4       age_at_onset
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>              <dbl>
    ##  1        3        62.5 male          16 carrier             66.8
    ##  2        5        66   male          16 non_carrier         68.7
    ##  3        7        66.5 male          18 non_carrier         74  
    ##  4       13        63.1 male          12 carrier             69  
    ##  5       14        58.4 female        20 non_carrier         66.2
    ##  6       18        67.8 male          16 non_carrier         69.8
    ##  7       22        67.3 female        20 carrier             74.6
    ##  8       26        64.8 female        20 carrier             71.1
    ##  9       30        66.3 female        12 non_carrier         73.1
    ## 10       39        68.3 female        16 carrier             70.2
    ## # ℹ 87 more rows

#### Discussion

Dataset “mci_baseline_df” has 6 variables: study_id, current_age, sex,
education, apoe4, age_at_onset. In this dataset, there are 483
participants. Of these, 97 devlops MCI. The average baseline age is
70.2628866. 29.8578199 % of women in the study are APOE4 carriers.

#### Import, Clean and Tidy Dataset `mci_amyloid.csv`

``` r
mci_amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na() |>
# Remove any participants who do not meet the stated inclusion criteria
  pivot_longer(
   baseline:time_8,
   names_to = "time",
   values_to = "time_value"
   ) |>
# Use pivot_longer function to switch from “wide” to “long” format
   arrange(time,study_id)
# Arrange the dataset according to time and study_id

mci_amyloid_df_unpivot= 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na()

mci_amyloid_df 
```

    ## # A tibble: 1,735 × 3
    ##    study_id time     time_value 
    ##       <dbl> <chr>    <chr>      
    ##  1        2 baseline 0.107481183
    ##  2        4 baseline 0.109251358
    ##  3        5 baseline 0.107950408
    ##  4        6 baseline 0.112426974
    ##  5       11 baseline 0.109119335
    ##  6       12 baseline 0.112042298
    ##  7       13 baseline 0.110300505
    ##  8       16 baseline 0.110218888
    ##  9       17 baseline 0.108399246
    ## 10       18 baseline 0.114137255
    ## # ℹ 1,725 more rows

#### Discussion

Dataset “mci_amyloid_df” has 3 variables: study_id, time, time_value. In
this dataset, there are 1735 rows.

## Join dataset

``` r
baseline_amyloid= merge(mci_baseline_df,mci_amyloid_df_unpivot, 
             by="study_id")
# Calculate participants appear in both datasets 
unqiue_baseline=setdiff(mci_baseline_df_noncleaned$id, mci_amyloid_df_unpivot$study_id)
length(unqiue_baseline)
```

    ## [1] 146

``` r
unqiue_amyloid=setdiff(mci_amyloid_df_unpivot$study_id, mci_baseline_df_noncleaned$id)
length(unqiue_amyloid)
```

    ## [1] 10

``` r
# Calculatethe number of unqiue participants in each datasets. 
baseline_amyloid_merge= merge(mci_baseline_df,mci_amyloid_df, 
             by="study_id")
# Merge two datasets so that only participants who appear in both datasets are retained 
```

#### Discussion

There are 146 unqiue partcipants in “MCI_baseline.csv” dataset and there
are 10 unique participants in “mci_amyloid.csv” dataset.

Only 66 participants appear in both the baseline and amyloid datasets.

For the resulting merged dataset, there are 8 variables, they are
study_id, current_age, sex, education, apoe4, age_at_onset, time,
time_value.

#### Export Result as CSV

``` r
write_csv(baseline_amyloid_merge,"baseline_amyloid_merge.csv")
```
