p8105_hw2_xw2962
================
Xiaoyu Wu
2023-09-26

``` r
library(tidyverse)
library(haven)
library(readxl)
```

## Problem One

#### Step One: Clean Data in `pols-month.csv`

``` r
pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(mon,into=c("year","month","day"),sep="-",convert=TRUE) |>
# Seperate mon into year, month and day 
   mutate(month=month.abb[as.numeric(month)]) |>
# Replace month number with month name 
  mutate(
   prez_gop=case_match(
     prez_gop,
     0~"dem",
     1~"gop",
   )) |>
  mutate(
   prez_dem=case_match(
     prez_dem,
     0~"gop",
     1~"dem",
   )) |>
  relocate(year, month,day,prez_gop,prez_dem) |>
  pivot_longer(
   prez_gop:prez_dem,
   names_to = "president_title",
   values_to = "president"
   ) |>
# Create a president variable taking values gop and dem, and remove prez_dem and prez_gop
   select(-day) |>
# Remove the day variable
   select(-president_title)
pols_df
```

    ## # A tibble: 1,644 × 9
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 Jan        23      51     253      23      45     198 dem      
    ##  2  1947 Jan        23      51     253      23      45     198 dem      
    ##  3  1947 Feb        23      51     253      23      45     198 dem      
    ##  4  1947 Feb        23      51     253      23      45     198 dem      
    ##  5  1947 Mar        23      51     253      23      45     198 dem      
    ##  6  1947 Mar        23      51     253      23      45     198 dem      
    ##  7  1947 Apr        23      51     253      23      45     198 dem      
    ##  8  1947 Apr        23      51     253      23      45     198 dem      
    ##  9  1947 May        23      51     253      23      45     198 dem      
    ## 10  1947 May        23      51     253      23      45     198 dem      
    ## # ℹ 1,634 more rows

#### Step Two: Clean Data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  mutate(date=as.Date(date,format="%m/%d/%y"),
         date=as.Date(ifelse(date>Sys.Date(),
                             format(date,"19y-%m-%d"),
                             format(date)))) |>
         separate(date,into=c("year","month","day")) |> 
# Use separate() to break up the variable mon into integer variables year, month, and day
   mutate(month=month.abb[as.numeric(month)],
   year=as.numeric(year)) |>
# Replace month number with month name
  select(-day) |> 
# Remove the day variable
  arrange(year, month) |>
# Arrange according to year and month
  relocate(year, month) 
# Organize so that year and month are the leading columns

snp_df
```

    ## # A tibble: 787 × 3
    ##     year month close
    ##    <dbl> <chr> <dbl>
    ##  1  1969 Apr   104. 
    ##  2  1969 Aug    95.5
    ##  3  1969 Dec    92.1
    ##  4  1969 Feb    98.1
    ##  5  1969 Jan   103. 
    ##  6  1969 Jul    91.8
    ##  7  1969 Jun    97.7
    ##  8  1969 Mar   102. 
    ##  9  1969 May   103. 
    ## 10  1969 Nov    93.8
    ## # ℹ 777 more rows

#### Step Three: Tidy Data in `unemployment.csv`

``` r
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |>
# Read in dataset 
  pivot_longer(
   jan:dec,
   names_to = "month",
   values_to = "unemployment_num"
   ) 
# Use pivot_longer function to switch from “wide” to “long” format;
unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month unemployment_num
    ##    <dbl> <chr>            <dbl>
    ##  1  1948 jan                3.4
    ##  2  1948 feb                3.8
    ##  3  1948 mar                4  
    ##  4  1948 apr                3.9
    ##  5  1948 may                3.5
    ##  6  1948 jun                3.6
    ##  7  1948 jul                3.6
    ##  8  1948 aug                3.9
    ##  9  1948 sep                3.8
    ## 10  1948 oct                3.7
    ## # ℹ 806 more rows

#### Join Datasets

``` r
pols_snp = 
  left_join(pols_df,snp_df,by = c("year","month"))
# Join the datasets by merging snp into pols
pols_snp_unemployment=
  left_join(pols_snp,unemployment_df,by = c("year","month"))
# Join unemployment_df to the result dataset from above
pols_snp_unemployment
```

    ## # A tibble: 1,644 × 11
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 Jan        23      51     253      23      45     198 dem          NA
    ##  2  1947 Jan        23      51     253      23      45     198 dem          NA
    ##  3  1947 Feb        23      51     253      23      45     198 dem          NA
    ##  4  1947 Feb        23      51     253      23      45     198 dem          NA
    ##  5  1947 Mar        23      51     253      23      45     198 dem          NA
    ##  6  1947 Mar        23      51     253      23      45     198 dem          NA
    ##  7  1947 Apr        23      51     253      23      45     198 dem          NA
    ##  8  1947 Apr        23      51     253      23      45     198 dem          NA
    ##  9  1947 May        23      51     253      23      45     198 dem          NA
    ## 10  1947 May        23      51     253      23      45     198 dem          NA
    ## # ℹ 1,634 more rows
    ## # ℹ 1 more variable: unemployment_num <dbl>

#### Short Description of Dataset

Dataset “pols_df” has 9 variables: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president. In this dataset, there
are 1644 rows. And there are 9 columns. Here we consider variables
“gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”, “sen_dem”, “rep_dem” and
“president” to be important for analysis.

Dataset “snp_df” has 3 variables: year, month, close. In this dataset,
there are 787 rows. And there are 3 columns. Here we consider variables
“close” to be important for analysis.

Dataset “unemployment_df” has 3 variables: year, month,
unemployment_num. In this dataset, there are 816 rows. And there are 3
columns. Here we consider variables “unemployment_num” to be important
for analysis.

The joining dataset “pols_snp_unemployment” has 11 variables: year,
month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president,
close, unemployment_num. In this dataset, there are 1644 rows. And there
are 11 columns. Here we consider variables “gov_gop”, “sen_gop”,
“rep_gop”, “gov_dem”, “sen_dem”, “rep_dem”, “president”,“close” and
“unemployment_num” to be important for analysis.

## Problem Two

#### Import, Clean, and Organize the Data for `Mr. Trash Wheel`

``` r
mr_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",range="A2:N549") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |>
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="mr_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification 
mr_trash_wheel_df
```

    ## # A tibble: 486 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 476 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Professor Trash Wheel`

``` r
professor_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",2,range="A2:M96") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="professor_trash_wheel") |>
  relocate(trash_wheel_name) |> 
# Add a variable for clear identification
  mutate(year=as.character("year"))
professor_trash_wheel_df
```

    ## # A tibble: 82 × 14
    ##    trash_wheel_name      dumpster month    year  date                weight_tons
    ##    <chr>                    <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 professor_trash_wheel        1 January  year  2017-01-02 00:00:00        1.79
    ##  2 professor_trash_wheel        2 January  year  2017-01-30 00:00:00        1.58
    ##  3 professor_trash_wheel        3 February year  2017-02-26 00:00:00        2.32
    ##  4 professor_trash_wheel        4 February year  2017-02-26 00:00:00        3.72
    ##  5 professor_trash_wheel        5 February year  2017-02-28 00:00:00        1.45
    ##  6 professor_trash_wheel        6 March    year  2017-03-30 00:00:00        1.71
    ##  7 professor_trash_wheel        7 April    year  2017-04-01 00:00:00        1.82
    ##  8 professor_trash_wheel        8 April    year  2017-04-20 00:00:00        2.37
    ##  9 professor_trash_wheel        9 May      year  2017-05-10 00:00:00        2.64
    ## 10 professor_trash_wheel       10 May      year  2017-05-26 00:00:00        2.78
    ## # ℹ 72 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Gwynnda Trash Wheel`

``` r
Gwynnda_trash_wheel_df=
  read_excel("./Trash Wheel Data.xlsx",4,range="A2:K108") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="Gwynnda_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification
Gwynnda_trash_wheel_df
```

    ## # A tibble: 17 × 12
    ##    trash_wheel_name    dumpster month   year date                weight_tons
    ##    <chr>                  <dbl> <chr>  <dbl> <dttm>                    <dbl>
    ##  1 Gwynnda_trash_wheel        1 July    2021 2021-07-03 00:00:00        0.93
    ##  2 Gwynnda_trash_wheel        2 July    2021 2021-07-07 00:00:00        2.26
    ##  3 Gwynnda_trash_wheel        3 July    2021 2021-07-07 00:00:00        1.62
    ##  4 Gwynnda_trash_wheel        4 July    2021 2021-07-16 00:00:00        1.76
    ##  5 Gwynnda_trash_wheel        5 July    2021 2021-07-30 00:00:00        1.53
    ##  6 Gwynnda_trash_wheel        6 August  2021 2021-08-11 00:00:00        2.06
    ##  7 Gwynnda_trash_wheel        7 August  2021 2021-08-14 00:00:00        1.9 
    ##  8 Gwynnda_trash_wheel        8 August  2021 2021-08-16 00:00:00        2.16
    ##  9 Gwynnda_trash_wheel        9 August  2021 2021-08-16 00:00:00        2.6 
    ## 10 Gwynnda_trash_wheel       10 August  2021 2021-08-17 00:00:00        3.21
    ## 11 Gwynnda_trash_wheel       11 August  2021 2021-08-17 00:00:00        2.44
    ## 12 Gwynnda_trash_wheel       12 August  2021 2021-08-18 00:00:00        2.62
    ## 13 Gwynnda_trash_wheel       13 August  2021 2021-08-19 00:00:00        2.92
    ## 14 Gwynnda_trash_wheel       14 August  2021 2021-08-19 00:00:00        2.93
    ## 15 Gwynnda_trash_wheel       15 August  2021 2021-08-20 00:00:00        3.31
    ## 16 Gwynnda_trash_wheel       16 August  2021 2021-08-24 00:00:00        2.7 
    ## 17 Gwynnda_trash_wheel       17 August  2021 2021-08-25 00:00:00        2.1 
    ## # ℹ 6 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   homes_powered <dbl>

``` r
Gwynnda_trash_wheel_df_july=filter(Gwynnda_trash_wheel_df,month=="July" )
Gwynnda_trash_wheel_df_july
```

    ## # A tibble: 5 × 12
    ##   trash_wheel_name    dumpster month  year date                weight_tons
    ##   <chr>                  <dbl> <chr> <dbl> <dttm>                    <dbl>
    ## 1 Gwynnda_trash_wheel        1 July   2021 2021-07-03 00:00:00        0.93
    ## 2 Gwynnda_trash_wheel        2 July   2021 2021-07-07 00:00:00        2.26
    ## 3 Gwynnda_trash_wheel        3 July   2021 2021-07-07 00:00:00        1.62
    ## 4 Gwynnda_trash_wheel        4 July   2021 2021-07-16 00:00:00        1.76
    ## 5 Gwynnda_trash_wheel        5 July   2021 2021-07-30 00:00:00        1.53
    ## # ℹ 6 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   homes_powered <dbl>

``` r
# Filter out the Gwynnda_trash_wheel data in july 
```

#### Combine these with the `Mr. Trash Wheel` Dataset to Create Single Tidy Dataset

``` r
mr_professor_Gwynnda=
  left_join(mr_trash_wheel_df,professor_trash_wheel_df,Gwynnda_trash_wheel_df,by=c("trash_wheel_name","month","dumpster","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","glass_bottles","grocery_bags","chip_bags","homes_powered"))
mr_professor_Gwynnda
```

    ## # A tibble: 486 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 476 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <dbl>,
    ## #   homes_powered <dbl>

#### Description

Dataset “mr_professor_Gwynnda” has 15 variables: trash_wheel_name,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
grocery_bags, chip_bags, sports_balls, homes_powered. In this dataset,
there are 486 rows or observations. And there are 15 columns or
variables.

Here, we consider “weight_tons”,“volume_cubic_yards” and “homes_powered”
to be key variables. The variable “weight_tons” has mean 3.2077778 and
standard deviation 0.7420151. The variable “volume_cubic_yards” has mean
15.3847737 and standard deviation 1.4366681. The variable
“homes_powered” has mean 53.462963 and standard deviation 12.3669181.

The total weight of trash collected by Professor Trash Wheel is 162.54.

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

## Problem Three

#### Import, Clean and Tidy Dataset `MCI_baseline.csv`

``` r
mci_baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  mutate(age_at_onset=as.numeric(age_at_onset)) |>
  filter(age_at_onset!=".") |> 
# Remove any participants who do not meet the stated inclusion criteria
  rename("study_id" = "id") 

mci_baseline_df_noncleaned = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
  mutate(sex = recode(sex, "1" = "male", "0" = "female"))

mci_baseline_df_female=filter(mci_baseline_df_noncleaned,sex=="female" )
# Filter out participants who are females 
mci_baseline_df_female_carriers=filter(mci_baseline_df_female, apoe4=="carrier")
# Filter out participants who are females and who have apoe4 carriers 
mci_baseline_df
```

    ## # A tibble: 97 × 6
    ##    study_id current_age sex    education apoe4       age_at_onset
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>              <dbl>
    ##  1        3        62.5 male          16 carrier             66.8
    ##  2        5        66   male          16 non_carrier         68.7
    ##  3        7        66.5 male          18 non_carrier         74  
    ##  4       13        63.1 male          12 carrier             69  
    ##  5       14        58.4 female        20 non_carrier         66.2
    ##  6       18        67.8 male          16 non_carrier         69.8
    ##  7       22        67.3 female        20 carrier             74.6
    ##  8       26        64.8 female        20 carrier             71.1
    ##  9       30        66.3 female        12 non_carrier         73.1
    ## 10       39        68.3 female        16 carrier             70.2
    ## # ℹ 87 more rows

#### Discussion

Dataset “mci_baseline_df” has 6 variables: study_id, current_age, sex,
education, apoe4, age_at_onset. In this dataset, there are 97
participants. Of these, 97 devlops MCI. The average baseline age is
70.2628866. 0 % of women in the study are APOE4 carriers.

#### Import, Clean and Tidy Dataset `mci_amyloid.csv`

``` r
mci_amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na() |>
# Remove any participants who do not meet the stated inclusion criteria
  pivot_longer(
   baseline:time_8,
   names_to = "time",
   values_to = "time_value"
   ) |>
# Use pivot_longer function to switch from “wide” to “long” format
   arrange(time,study_id)
# Arrange the dataset according to time and study_id

mci_amyloid_df_unpivot= 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  drop_na()

mci_amyloid_df 
```

    ## # A tibble: 1,735 × 3
    ##    study_id time     time_value 
    ##       <dbl> <chr>    <chr>      
    ##  1        2 baseline 0.107481183
    ##  2        4 baseline 0.109251358
    ##  3        5 baseline 0.107950408
    ##  4        6 baseline 0.112426974
    ##  5       11 baseline 0.109119335
    ##  6       12 baseline 0.112042298
    ##  7       13 baseline 0.110300505
    ##  8       16 baseline 0.110218888
    ##  9       17 baseline 0.108399246
    ## 10       18 baseline 0.114137255
    ## # ℹ 1,725 more rows

#### Discussion

Dataset “mci_amyloid_df” has 3 variables: study_id, time, time_value. In
this dataset, there are 1735 rows.

## Join dataset

``` r
baseline_amyloid= merge(mci_baseline_df,mci_amyloid_df_unpivot, 
             by="study_id")
# Calculate participants appear in both datasets 
unqiue_baseline=setdiff(mci_baseline_df_noncleaned$id, mci_amyloid_df_unpivot$study_id)
length(unqiue_baseline)
```

    ## [1] 146

``` r
unqiue_amyloid=setdiff(mci_amyloid_df_unpivot$study_id, mci_baseline_df_noncleaned$id)
length(unqiue_amyloid)
```

    ## [1] 10

``` r
# Calculatethe number of unqiue participants in each datasets. 
baseline_amyloid_merge= merge(mci_baseline_df,mci_amyloid_df, 
             by="study_id")
# Merge two datasets so that only participants who appear in both datasets are retained 
```

#### Discussion

There are 146 unqiue partcipants in “MCI_baseline.csv” dataset and there
are 10 unique participants in “mci_amyloid.csv” dataset.

Only 66 participants appear in both the baseline and amyloid datasets.

For the resulting merged dataset, there are 8 variables, they are
study_id, current_age, sex, education, apoe4, age_at_onset, time,
time_value.

#### Export Result as CSV

``` r
write_csv(baseline_amyloid_merge,"baseline_amyloid_merge.csv")
```
