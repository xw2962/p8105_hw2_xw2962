p8105_hw2_xw2962
================
Xiaoyu Wu
2023-09-26

``` r
library(tidyverse)
library(haven)
library(readxl)
```

## Problem One

#### Step One: Clean Data in `pols-month.csv`

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
# Read in dataset 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
# seperate month into year, month_num and day. 
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
# create a variable called "president" by recoding prez_gop
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
# arrange table and delete day and columns starts with "prez" 
pols_df
```

    ## # A tibble: 822 × 11
    ##     year month     month_num gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <int> <chr>         <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 January           1      23      51     253      23      45     198
    ##  2  1947 February          2      23      51     253      23      45     198
    ##  3  1947 March             3      23      51     253      23      45     198
    ##  4  1947 April             4      23      51     253      23      45     198
    ##  5  1947 May               5      23      51     253      23      45     198
    ##  6  1947 June              6      23      51     253      23      45     198
    ##  7  1947 July              7      23      51     253      23      45     198
    ##  8  1947 August            8      23      51     253      23      45     198
    ##  9  1947 September         9      23      51     253      23      45     198
    ## 10  1947 October          10      23      51     253      23      45     198
    ## # ℹ 812 more rows
    ## # ℹ 2 more variables: president <chr>, month_abb <chr>

#### Step Two: Clean Data in `snp.csv`

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv",
  col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
# Use separate() to break up the variable mon into integer variables year, month, and day
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
# year > 2023 is "fail" and should follow "year - 100"; ifesle is "pass" and should give "year" directly
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month    close
    ##    <dbl> <chr>    <dbl>
    ##  1  2015 July     2080.
    ##  2  2015 June     2063.
    ##  3  2015 May      2107.
    ##  4  2015 April    2086.
    ##  5  2015 March    2068.
    ##  6  2015 February 2104.
    ##  7  2015 January  1995.
    ##  8  2014 December 2059.
    ##  9  2014 November 2068.
    ## 10  2014 October  2018.
    ## # ℹ 777 more rows

#### Step Three: Tidy Data in `unemployment.csv`

``` r
unemployment_df= 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)

unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemployment
    ##    <dbl> <chr>            <dbl>
    ##  1  1948 January            3.4
    ##  2  1948 February           3.8
    ##  3  1948 March              4  
    ##  4  1948 April              3.9
    ##  5  1948 May                3.5
    ##  6  1948 June               3.6
    ##  7  1948 July               3.6
    ##  8  1948 August             3.9
    ##  9  1948 September          3.8
    ## 10  1948 October            3.7
    ## # ℹ 806 more rows

#### Join Datasets

``` r
pols_snp = 
  left_join(pols_df,snp_df,by=c("year","month")) |> 
  arrange(year,month)
# Join the datasets by merging snp into pols
pols_snp_unemployment=
  left_join(pols_snp,unemployment_df,by=c("year","month")) |> 
  arrange(year,month) |>
  select(year, month, everything(), -month_num, -month_abb) 
# Join unemployment_df to the result dataset from above
pols_snp_unemployment
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 April        23      51     253      23      45     198 dem          NA
    ##  2  1947 August       23      51     253      23      45     198 dem          NA
    ##  3  1947 Decemb…      24      51     253      23      45     198 dem          NA
    ##  4  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  5  1947 January      23      51     253      23      45     198 dem          NA
    ##  6  1947 July         23      51     253      23      45     198 dem          NA
    ##  7  1947 June         23      51     253      23      45     198 dem          NA
    ##  8  1947 March        23      51     253      23      45     198 dem          NA
    ##  9  1947 May          23      51     253      23      45     198 dem          NA
    ## 10  1947 Novemb…      24      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

#### Short Description of Dataset

Dataset “pols_df” has 11 variables: year, month, month_num, gov_gop,
sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, month_abb. In
this dataset, there are 822 rows. And there are 11 columns. Here we
consider variables “gov_gop”, “sen_gop”, “rep_gop”, “gov_dem”,
“sen_dem”, “rep_dem” and “president” to be important for analysis.

Dataset “snp_df” has 3 variables: year, month, close. In this dataset,
there are 787 rows. And there are 3 columns. Here we consider variables
“close” to be important for analysis.

Dataset “unemployment_df” has 3 variables: year, month, unemployment. In
this dataset, there are 816 rows. And there are 3 columns. Here we
consider variables “unemployment_num” to be important for analysis.

The joining dataset “pols_snp_unemployment” has 11 variables: year,
month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president,
close, unemployment. In this dataset, there are 822 rows. And there are
11 columns. Here we consider variables “gov_gop”, “sen_gop”, “rep_gop”,
“gov_dem”, “sen_dem”, “rep_dem”, “president”,“close” and
“unemployment_num” to be important for analysis.

## Problem Two

#### Import, Clean, and Organize the Data for `Mr. Trash Wheel`

``` r
mr_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",range="A2:N586") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  drop_na() |> 
# Omit rows that do not include dumpster-specific data
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |>
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="mr_trash_wheel") |>
  relocate(trash_wheel_name)
# Add a variable for clear identification 
mr_trash_wheel_df
```

    ## # A tibble: 584 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Professor Trash Wheel`

``` r
professor_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",2,range="A2:M108") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="professor_trash_wheel") |>
  relocate(trash_wheel_name) |> 
# Add a variable for clear identification
  mutate(year=as.character("year"))
professor_trash_wheel_df
```

    ## # A tibble: 106 × 14
    ##    trash_wheel_name      dumpster month    year  date                weight_tons
    ##    <chr>                    <dbl> <chr>    <chr> <dttm>                    <dbl>
    ##  1 professor_trash_wheel        1 January  year  2017-01-02 00:00:00        1.79
    ##  2 professor_trash_wheel        2 January  year  2017-01-30 00:00:00        1.58
    ##  3 professor_trash_wheel        3 February year  2017-02-26 00:00:00        2.32
    ##  4 professor_trash_wheel        4 February year  2017-02-26 00:00:00        3.72
    ##  5 professor_trash_wheel        5 February year  2017-02-28 00:00:00        1.45
    ##  6 professor_trash_wheel        6 March    year  2017-03-30 00:00:00        1.71
    ##  7 professor_trash_wheel        7 April    year  2017-04-01 00:00:00        1.82
    ##  8 professor_trash_wheel        8 April    year  2017-04-20 00:00:00        2.37
    ##  9 professor_trash_wheel        9 May      year  2017-05-10 00:00:00        2.64
    ## 10 professor_trash_wheel       10 May      year  2017-05-26 00:00:00        2.78
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, homes_powered <dbl>

#### Import, Clean, and Organize the Data for `Gwynnda Trash Wheel`

``` r
Gwynnda_trash_wheel_df=
  read_excel("./Trash Wheel Collection Data.xlsx",4,range="A2:L157") |> 
# Specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel
  janitor::clean_names() |>  
# Use reasonable variable names
  mutate(
    homes_powered = ((weight_tons*500)/30
    )) |> 
# Update the data to include a new homes_powered variable based on the noted calculation
  mutate(trash_wheel_name="Gwynnda_trash_wheel") |>
  mutate(year=as.character(year)) |>
  relocate(trash_wheel_name)
# Add a variable for clear identification
Gwynnda_trash_wheel_df
```

    ## # A tibble: 155 × 13
    ##    trash_wheel_name    dumpster month  year  date                weight_tons
    ##    <chr>                  <dbl> <chr>  <chr> <dttm>                    <dbl>
    ##  1 Gwynnda_trash_wheel        1 July   2021  2021-07-03 00:00:00        0.93
    ##  2 Gwynnda_trash_wheel        2 July   2021  2021-07-07 00:00:00        2.26
    ##  3 Gwynnda_trash_wheel        3 July   2021  2021-07-07 00:00:00        1.62
    ##  4 Gwynnda_trash_wheel        4 July   2021  2021-07-16 00:00:00        1.76
    ##  5 Gwynnda_trash_wheel        5 July   2021  2021-07-30 00:00:00        1.53
    ##  6 Gwynnda_trash_wheel        6 August 2021  2021-08-11 00:00:00        2.06
    ##  7 Gwynnda_trash_wheel        7 August 2021  2021-08-14 00:00:00        1.9 
    ##  8 Gwynnda_trash_wheel        8 August 2021  2021-08-16 00:00:00        2.16
    ##  9 Gwynnda_trash_wheel        9 August 2021  2021-08-16 00:00:00        2.6 
    ## 10 Gwynnda_trash_wheel       10 August 2021  2021-08-17 00:00:00        3.21
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
Gwynnda_trash_wheel_df_july=filter(Gwynnda_trash_wheel_df,month=="July" )
Gwynnda_trash_wheel_df_july_year=filter(Gwynnda_trash_wheel_df_july,year=="2021")
# Filter out the Gwynnda_trash_wheel data in july 
```

#### Combine these with the `Mr. Trash Wheel` Dataset to Create Single Tidy Dataset

``` r
mr_professor_Gwynnda=
  bind_rows(mr_trash_wheel_df,professor_trash_wheel_df,Gwynnda_trash_wheel_df) |>
  janitor::clean_names() |>
  select(trash_wheel_name,everything())

mr_professor_Gwynnda
```

    ## # A tibble: 845 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 mr_trash_wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 mr_trash_wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 mr_trash_wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 mr_trash_wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 mr_trash_wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 mr_trash_wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 mr_trash_wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 mr_trash_wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 mr_trash_wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 mr_trash_wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

#### Description

The data “mr_trash_wheel_df” is from the Mr.Trash Wheel sheet from
May.2014 to July. 2022, which contains trash_wheel_name, dumpster,
month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered and the number of observations is 584.

The data “professor_trash_wheel_df” is from the Professor Trash Wheel
sheet from January.2017 to July. 2022, which contains trash_wheel_name,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, homes_powered and the number of observations is
106.

The data “Gwynnda_trash_wheel_df” is from the Gwynnda Trash Wheel sheet
from July.2021 to July. 2022, which contains trash_wheel_name, dumpster,
month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, plastic_bags, wrappers, homes_powered and
the number of observations is 155.

Dataset “mr_professor_Gwynnda” has 15 variables: trash_wheel_name,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, sports_balls, homes_powered. In this dataset,
there are 845 rows or observations. And there are 15 columns or
variables.

Here, we consider “weight_tons”,“volume_cubic_yards” and “homes_powered”
to be key variables. The variable “weight_tons” has mean 3.0094793 and
standard deviation 0.8135678. The variable “volume_cubic_yards” has mean
15.1349112 and standard deviation 1.3457939. The variable
“homes_powered” has mean 50.1579882 and standard deviation 13.5594639.

The total weight of trash collected by Professor Trash Wheel is 216.26.

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

## Problem Three

#### Import, Clean and Tidy Dataset `MCI_baseline.csv`

``` r
mci_baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  filter(current_age<age_at_onset|age_at_onset==".") |> 
# Remove any participants who do not meet the stated inclusion criteria.
  rename("study_id" = "id") 

 mci_baseline_df_noncleaned = 
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |> 
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
  rename("study_id" = "id")
 
mci_baseline_df_develop=
  read_csv("./data_mci/MCI_baseline.csv",skip=1) |> 
  janitor::clean_names() |>
# Read in dataset 
  mutate(sex = recode(sex, "1" = "male", "0" = "female")) |>
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non_carrier")) |>
# Recode sex and APOE4 carrier status
  filter(current_age<age_at_onset) |> 
# Remove any participants who do not meet the stated inclusion criteria and filter out whose value is "."
  rename("study_id" = "id") 

mci_baseline_df_female=filter(mci_baseline_df,sex=="female" )
# Filter out participants who are females 
mci_baseline_df_female_carriers=filter(mci_baseline_df_female,apoe4=="carrier")
# Filter out participants who are females and who have apoe4 carriers 

mci_baseline_df
```

    ## # A tibble: 479 × 6
    ##    study_id current_age sex    education apoe4       age_at_onset
    ##       <dbl>       <dbl> <chr>      <dbl> <chr>       <chr>       
    ##  1        1        63.1 female        16 carrier     .           
    ##  2        2        65.6 female        20 carrier     .           
    ##  3        3        62.5 male          16 carrier     66.8        
    ##  4        4        69.8 female        16 non_carrier .           
    ##  5        5        66   male          16 non_carrier 68.7        
    ##  6        6        62.5 male          16 non_carrier .           
    ##  7        7        66.5 male          18 non_carrier 74          
    ##  8        8        67.2 female        18 non_carrier .           
    ##  9        9        66.7 female        16 non_carrier .           
    ## 10       10        64.1 female        18 non_carrier .           
    ## # ℹ 469 more rows

#### Discussion

We first imported and cleaned the dataset. Then we recoded the “sex” and
“APOE4” into meaningful characters. And we removed any participants who
do not meet the stated inclusion criteria.

Dataset “mci_baseline_df” has 6 variables: study_id, current_age, sex,
education, apoe4, age_at_onset.

In this dataset, there are 479 participants. Of these, 93 devlops MCI
eventually.

The average baseline age is 65.0467909. 30 % of women in the study are
APOE4 carriers.

#### Import, Clean and Tidy Dataset `mci_amyloid.csv`

``` r
mci_amyloid_df = 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() |>
# Read in dataset 
  pivot_longer(
   baseline:time_8,
   names_to = "time",
   values_to = "time_value"
   ) |>
# Use pivot_longer function to switch from “wide” to “long” format
   arrange(time,study_id) 
# Arrange the dataset according to time and study_id

mci_amyloid_df_unpivot= 
  read_csv("./data_mci/mci_amyloid.csv",skip = 1) |> 
  janitor::clean_names() 
# Read in dataset 
 
mci_amyloid_df 
```

    ## # A tibble: 2,435 × 3
    ##    study_id time     time_value 
    ##       <dbl> <chr>    <chr>      
    ##  1        1 baseline 0.1105487  
    ##  2        2 baseline 0.107481183
    ##  3        3 baseline 0.106087034
    ##  4        4 baseline 0.109251358
    ##  5        5 baseline 0.107950408
    ##  6        6 baseline 0.112426974
    ##  7        7 baseline 0.112246391
    ##  8        8 baseline 0.109563372
    ##  9        9 baseline 0.112101884
    ## 10       10 baseline 0.1116094  
    ## # ℹ 2,425 more rows

#### Discussion

We first read in the dataset. And then we use pivot_longer function to
switch from “wide” to “long” format. Finally, we arrange the dataset
according to time and study_id.

Dataset “mci_amyloid_df” has 3 variables: study_id, time, time_value. In
this dataset, there are 2435 rows.

## Join dataset

``` r
baseline_amyloid= inner_join(mci_baseline_df,mci_amyloid_df_unpivot, 
             by="study_id")
# Calculate participants appear in both datasets 
unqiue_baseline=setdiff(mci_baseline_df$study_id, mci_amyloid_df_unpivot$study_id)
length(unqiue_baseline)
```

    ## [1] 8

``` r
unqiue_amyloid=setdiff(mci_amyloid_df_unpivot$study_id, mci_baseline_df$study_id)
length(unqiue_amyloid)
```

    ## [1] 16

``` r
# Calculatethe number of unqiue participants in each datasets. 
baseline_amyloid_merge= inner_join(mci_baseline_df,mci_amyloid_df, 
             by="study_id")
# Merge two datasets so that only participants who appear in both datasets are retained
```

#### Discussion

There are 8 unqiue partcipants in “MCI_baseline.csv” dataset and there
are 16 unique participants in “mci_amyloid.csv” dataset.

Only 471 participants appear in both the baseline and amyloid datasets.

For the resulting merged dataset, there are 8 variables, they are
study_id, current_age, sex, education, apoe4, age_at_onset, time,
time_value.

#### Export Result as CSV

``` r
write_csv(baseline_amyloid_merge,"baseline_amyloid_merge.csv")
```
